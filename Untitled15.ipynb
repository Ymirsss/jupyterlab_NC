{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6d046-7a2f-45a6-980f-aafb527cec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from dalle_pytorch import VQGanVAE, DALLE, DiscreteVAE\n",
    "from dalle_pytorch.tokenizer import tokenizer\n",
    "from einops import repeat\n",
    "from dalle_nc import DALLE, DiscreteVAE\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# model\n",
    "vae = DiscreteVAE(\n",
    "    image_size = 8,\n",
    "    num_layers = 3,\n",
    "    num_tokens = 8192,\n",
    "    codebook_dim = 1024,\n",
    "    hidden_dim = 64,\n",
    "    num_resnet_blocks = 1,\n",
    "    temperature = 0.9\n",
    ")\n",
    "\n",
    "dalle = DALLE(\n",
    "    dim = 1024,\n",
    "    vae = vae,                  # automatically infer (1) image sequence length and (2) number of image tokens\n",
    "    num_text_tokens = 100000,    # vocab size for text\n",
    "    text_seq_len = 256,         # text sequence length\n",
    "    depth = 12,                 # should aim to be 64\n",
    "    heads = 16,                 # attention heads\n",
    "    dim_head = 64,              # attention head dimension\n",
    "    attn_dropout = 0.1,         # attention dropout\n",
    "    ff_dropout = 0.1            # feedforward dropout\n",
    ")\n",
    "# [NeuralCoder] pytorch_inc_dynamic_quant for dalle [Beginning Line]\n",
    "if \"GraphModule\" not in str(type(dalle)):\n",
    "    from neural_compressor.conf.config import QuantConf\n",
    "    from neural_compressor.experimental import Quantization, common\n",
    "    quant_config = QuantConf()\n",
    "    quant_config.usr_cfg.quantization.approach = \"post_training_dynamic_quant\"\n",
    "    quant_config.usr_cfg.model.framework = \"pytorch\"\n",
    "    quantizer = Quantization(quant_config)\n",
    "    quantizer.model = common.Model(dalle)\n",
    "    dalle = quantizer()\n",
    "    dalle = dalle.model\n",
    "    dalle.eval()\n",
    "# [NeuralCoder] pytorch_inc_dynamic_quant for dalle [Ending Line]\n",
    "\n",
    "dalle.eval()\n",
    "\n",
    "# real data for DALLE image generation\n",
    "files = glob.glob(\"/home2/longxin/Neural_Coder_EXT/real_text.txt\")\n",
    "\n",
    "# create dataloader\n",
    "input_list = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        texts = open(file, 'r').read().split('\\n')\n",
    "        for text in texts:\n",
    "            print(text)\n",
    "\n",
    "            num_images = 1\n",
    "\n",
    "            top_k = 0.9\n",
    "\n",
    "            image_size = vae.image_size\n",
    "\n",
    "            texts = text.split('|')\n",
    "\n",
    "            for j, text in tqdm(enumerate(texts)):\n",
    "                text_tokens = tokenizer.tokenize([text], 256).to('cpu')\n",
    "\n",
    "                text_tokens = repeat(text_tokens, '() n -> b n', b=num_images)\n",
    "\n",
    "                for text_chunk in tqdm(text_tokens):\n",
    "                    d = {}\n",
    "                    d[\"text\"] = text_chunk\n",
    "                    d[\"filter_thres\"] = top_k\n",
    "                    input_list.append(d)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = input_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset)\n",
    "\n",
    "# inference\n",
    "with torch.no_grad():\n",
    "    for step, (inputs, labels) in enumerate(dataloader):\n",
    "        print(\"running inference ...\")\n",
    "        # [NeuralCoder] pytorch_benchmark [Beginning Line] \n",
    "        if not False:\n",
    "            try:\n",
    "                time\n",
    "                time_nc = time.time\n",
    "            except:\n",
    "                from time import time as time_nc\n",
    "            count_iter_ = 0\n",
    "            total_time_ = 0\n",
    "            num_iter_ = 15\n",
    "            num_warmup_iter_ = 5\n",
    "            list_batch_time_ = []\n",
    "            for i_ in range(num_iter_):\n",
    "                count_iter_ = count_iter_ + 1\n",
    "                if count_iter_ > num_warmup_iter_:\n",
    "                    t1_ = time_nc()\n",
    "                try:\n",
    "                    torch\n",
    "                    no_grad = torch.no_grad\n",
    "                except:\n",
    "                    from torch import no_grad\n",
    "                with no_grad():\n",
    "        # [NeuralCoder] pytorch_benchmark [Ending Line]\n",
    "                    output = dalle(**inputs)\n",
    "        # [NeuralCoder] pytorch_benchmark [Beginning Line] \n",
    "                if count_iter_ > num_warmup_iter_:\n",
    "                    t2_ = time_nc()\n",
    "                    batch_time_ = t2_ - t1_\n",
    "                    list_batch_time_.append(batch_time_)\n",
    "                    total_time_ = total_time_ + batch_time_\n",
    "            print(\"Neural_Coder_Bench_IPS: \", round((num_iter_ - num_warmup_iter_) / total_time_, 3))\n",
    "            print(\"Neural_Coder_Bench_MSPI: \", round(total_time_ / (num_iter_ - num_warmup_iter_) * 1000, 3))\n",
    "            list_batch_time_.sort()\n",
    "            p50_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.50) - 1] * 1000\n",
    "            p90_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.90) - 1] * 1000\n",
    "            p99_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.99) - 1] * 1000\n",
    "            print(\"Neural_Coder_Bench_P50: \", round(p50_latency_, 3))\n",
    "            print(\"Neural_Coder_Bench_P90: \", round(p90_latency_, 3))\n",
    "            print(\"Neural_Coder_Bench_P99: \", round(p99_latency_, 3))\n",
    "            quit()\n",
    "        else:\n",
    "            output = dalle(**inputs)\n",
    "        # [NeuralCoder] pytorch_benchmark [Ending Line]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
