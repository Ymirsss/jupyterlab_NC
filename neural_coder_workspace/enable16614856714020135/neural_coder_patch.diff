--- /home2/longxin/Neural_Coder_EXT/tmp.py	2022-08-26 11:47:51.377004016 +0800
+++ /home2/longxin/Neural_Coder_EXT/tmp_nc_enabled.py	2022-08-26 11:48:11.205930610 +0800
@@ -2,11 +2,66 @@
 import torch
 import torchvision.models as models
 model = models.resnet50(pretrained=True)
+# [NeuralCoder] pytorch_inc_dynamic_quant for model [Beginning Line]
+if "GraphModule" not in str(type(model)):
+    from neural_compressor.conf.config import QuantConf
+    from neural_compressor.experimental import Quantization, common
+    quant_config = QuantConf()
+    quant_config.usr_cfg.quantization.approach = "post_training_dynamic_quant"
+    quant_config.usr_cfg.model.framework = "pytorch"
+    quantizer = Quantization(quant_config)
+    quantizer.model = common.Model(model)
+    model = quantizer()
+    model = model.model
+    model.eval()
+# [NeuralCoder] pytorch_inc_dynamic_quant for model [Ending Line]
 model.eval()
-batch_size = 1
+batch_size = 112
 input = torch.rand(batch_size, 3, 224, 224)
 with torch.no_grad():
-    model(input)
+    # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+    if not False:
+        try:
+            time
+            time_nc = time.time
+        except:
+            from time import time as time_nc
+        count_iter_ = 0
+        total_time_ = 0
+        num_iter_ = 15
+        num_warmup_iter_ = 5
+        list_batch_time_ = []
+        for i_ in range(num_iter_):
+            count_iter_ = count_iter_ + 1
+            if count_iter_ > num_warmup_iter_:
+                t1_ = time_nc()
+            try:
+                torch
+                no_grad = torch.no_grad
+            except:
+                from torch import no_grad
+            with no_grad():
+    # [NeuralCoder] pytorch_benchmark [Ending Line]
+                model(input)
+    # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+            if count_iter_ > num_warmup_iter_:
+                t2_ = time_nc()
+                batch_time_ = t2_ - t1_
+                list_batch_time_.append(batch_time_)
+                total_time_ = total_time_ + batch_time_
+        print("Neural_Coder_Bench_IPS: ", round((num_iter_ - num_warmup_iter_) / total_time_, 3))
+        print("Neural_Coder_Bench_MSPI: ", round(total_time_ / (num_iter_ - num_warmup_iter_) * 1000, 3))
+        list_batch_time_.sort()
+        p50_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.50) - 1] * 1000
+        p90_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.90) - 1] * 1000
+        p99_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.99) - 1] * 1000
+        print("Neural_Coder_Bench_P50: ", round(p50_latency_, 3))
+        print("Neural_Coder_Bench_P90: ", round(p90_latency_, 3))
+        print("Neural_Coder_Bench_P99: ", round(p99_latency_, 3))
+        quit()
+    else:
+        model(input)
+    # [NeuralCoder] pytorch_benchmark [Ending Line]
 
 
 
