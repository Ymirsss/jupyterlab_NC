--- /home2/longxin/Neural_Coder_EXT/tmp.py	2022-08-19 10:31:22.628983485 +0800
+++ /home2/longxin/Neural_Coder_EXT/tmp_nc_enabled.py	2022-08-19 10:31:45.598226366 +0800
@@ -15,10 +15,65 @@ if "GraphModule" not in str(type(model))
     model = model.model
     model.eval()
 # [NeuralCoder] pytorch_inc_dynamic_quant for model [Ending Line]
+# [NeuralCoder] pytorch_inc_dynamic_quant for model [Beginning Line]
+if "GraphModule" not in str(type(model)):
+    from neural_compressor.conf.config import QuantConf
+    from neural_compressor.experimental import Quantization, common
+    quant_config = QuantConf()
+    quant_config.usr_cfg.quantization.approach = "post_training_dynamic_quant"
+    quant_config.usr_cfg.model.framework = "pytorch"
+    quantizer = Quantization(quant_config)
+    quantizer.model = common.Model(model)
+    model = quantizer()
+    model = model.model
+    model.eval()
+# [NeuralCoder] pytorch_inc_dynamic_quant for model [Ending Line]
 model.eval()
 input = torch.rand(1, 3, 224, 224)
 with torch.no_grad():
-        output = model(input)
+        # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+        if not False:
+            try:
+                time
+                time_nc = time.time
+            except:
+                from time import time as time_nc
+            count_iter_ = 0
+            total_time_ = 0
+            num_iter_ = 10
+            num_warmup_iter_ = 5
+            list_batch_time_ = []
+            for i_ in range(num_iter_):
+                count_iter_ = count_iter_ + 1
+                if count_iter_ > num_warmup_iter_:
+                    t1_ = time_nc()
+                try:
+                    torch
+                    no_grad = torch.no_grad
+                except:
+                    from torch import no_grad
+                with no_grad():
+        # [NeuralCoder] pytorch_benchmark [Ending Line]
+                    output = model(input)
+        # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+                if count_iter_ > num_warmup_iter_:
+                    t2_ = time_nc()
+                    batch_time_ = t2_ - t1_
+                    list_batch_time_.append(batch_time_)
+                    total_time_ = total_time_ + batch_time_
+            print("Neural_Coder_Bench_IPS: ", round((num_iter_ - num_warmup_iter_) / total_time_, 3))
+            print("Neural_Coder_Bench_MSPI: ", round(total_time_ / (num_iter_ - num_warmup_iter_) * 1000, 3))
+            list_batch_time_.sort()
+            p50_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.50) - 1] * 1000
+            p90_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.90) - 1] * 1000
+            p99_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.99) - 1] * 1000
+            print("Neural_Coder_Bench_P50: ", round(p50_latency_, 3))
+            print("Neural_Coder_Bench_P90: ", round(p90_latency_, 3))
+            print("Neural_Coder_Bench_P99: ", round(p99_latency_, 3))
+            quit()
+        else:
+            output = model(input)
+        # [NeuralCoder] pytorch_benchmark [Ending Line]
 
 # this is the beginning of a single code snippet
 
