--- /home2/longxin/Neural_Coder_EXT/tmp.py	2022-08-31 20:27:44.300371526 +0800
+++ /home2/longxin/Neural_Coder_EXT/tmp_nc_enabled.py	2022-08-31 20:27:59.513862193 +0800
@@ -171,7 +171,7 @@ def main_worker(gpu, ngpus_per_node, arg
             # When using a single GPU per process and per
             # DistributedDataParallel, we need to divide the batch size
             # ourselves based on the total number of GPUs of the current node.
-            args.batch_size = int(args.batch_size / ngpus_per_node)
+            args.batch_size = 112
             args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)
             model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])
         else:
@@ -262,11 +262,11 @@ def main_worker(gpu, ngpus_per_node, arg
         val_sampler = None
 
     train_loader = torch.utils.data.DataLoader(
-        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),
+        train_dataset, batch_size=112, shuffle=(train_sampler is None),
         num_workers=args.workers, pin_memory=True, sampler=train_sampler)
 
     val_loader = torch.utils.data.DataLoader(
-        val_dataset, batch_size=args.batch_size, shuffle=False,
+        val_dataset, batch_size=112, shuffle=False,
         num_workers=args.workers, pin_memory=True, sampler=val_sampler)
 
     if args.evaluate:
@@ -327,7 +327,49 @@ def train(train_loader, model, criterion
             target = target.cuda(args.gpu, non_blocking=True)
 
         # compute output
-        output = model(images)
+        # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+        if not False:
+            try:
+                time
+                time_nc = time.time
+            except:
+                from time import time as time_nc
+            count_iter_ = 0
+            total_time_ = 0
+            num_iter_ = 15
+            num_warmup_iter_ = 5
+            list_batch_time_ = []
+            for i_ in range(num_iter_):
+                count_iter_ = count_iter_ + 1
+                if count_iter_ > num_warmup_iter_:
+                    t1_ = time_nc()
+                try:
+                    torch
+                    no_grad = torch.no_grad
+                except:
+                    from torch import no_grad
+                with no_grad():
+        # [NeuralCoder] pytorch_benchmark [Ending Line]
+                    output = model(images)
+        # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+                if count_iter_ > num_warmup_iter_:
+                    t2_ = time_nc()
+                    batch_time_ = t2_ - t1_
+                    list_batch_time_.append(batch_time_)
+                    total_time_ = total_time_ + batch_time_
+            print("Neural_Coder_Bench_IPS: ", round((num_iter_ - num_warmup_iter_) / total_time_, 3))
+            print("Neural_Coder_Bench_MSPI: ", round(total_time_ / (num_iter_ - num_warmup_iter_) * 1000, 3))
+            list_batch_time_.sort()
+            p50_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.50) - 1] * 1000
+            p90_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.90) - 1] * 1000
+            p99_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.99) - 1] * 1000
+            print("Neural_Coder_Bench_P50: ", round(p50_latency_, 3))
+            print("Neural_Coder_Bench_P90: ", round(p90_latency_, 3))
+            print("Neural_Coder_Bench_P99: ", round(p99_latency_, 3))
+            quit()
+        else:
+            output = model(images)
+        # [NeuralCoder] pytorch_benchmark [Ending Line]
         loss = criterion(output, target)
 
         # measure accuracy and record loss
@@ -362,7 +404,49 @@ def validate(val_loader, model, criterio
                     target = target.cuda(args.gpu, non_blocking=True)
 
                 # compute output
-                output = model(images)
+                # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+                if not False:
+                    try:
+                        time
+                        time_nc = time.time
+                    except:
+                        from time import time as time_nc
+                    count_iter_ = 0
+                    total_time_ = 0
+                    num_iter_ = 15
+                    num_warmup_iter_ = 5
+                    list_batch_time_ = []
+                    for i_ in range(num_iter_):
+                        count_iter_ = count_iter_ + 1
+                        if count_iter_ > num_warmup_iter_:
+                            t1_ = time_nc()
+                        try:
+                            torch
+                            no_grad = torch.no_grad
+                        except:
+                            from torch import no_grad
+                        with no_grad():
+                # [NeuralCoder] pytorch_benchmark [Ending Line]
+                            output = model(images)
+                # [NeuralCoder] pytorch_benchmark [Beginning Line] 
+                        if count_iter_ > num_warmup_iter_:
+                            t2_ = time_nc()
+                            batch_time_ = t2_ - t1_
+                            list_batch_time_.append(batch_time_)
+                            total_time_ = total_time_ + batch_time_
+                    print("Neural_Coder_Bench_IPS: ", round((num_iter_ - num_warmup_iter_) / total_time_, 3))
+                    print("Neural_Coder_Bench_MSPI: ", round(total_time_ / (num_iter_ - num_warmup_iter_) * 1000, 3))
+                    list_batch_time_.sort()
+                    p50_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.50) - 1] * 1000
+                    p90_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.90) - 1] * 1000
+                    p99_latency_ = list_batch_time_[int(len(list_batch_time_) * 0.99) - 1] * 1000
+                    print("Neural_Coder_Bench_P50: ", round(p50_latency_, 3))
+                    print("Neural_Coder_Bench_P90: ", round(p90_latency_, 3))
+                    print("Neural_Coder_Bench_P99: ", round(p99_latency_, 3))
+                    quit()
+                else:
+                    output = model(images)
+                # [NeuralCoder] pytorch_benchmark [Ending Line]
                 loss = criterion(output, target)
 
                 # measure accuracy and record loss
@@ -399,7 +483,7 @@ def validate(val_loader, model, criterio
         aux_val_dataset = Subset(val_loader.dataset,
                                  range(len(val_loader.sampler) * args.world_size, len(val_loader.dataset)))
         aux_val_loader = torch.utils.data.DataLoader(
-            aux_val_dataset, batch_size=args.batch_size, shuffle=False,
+            aux_val_dataset, batch_size=112, shuffle=False,
             num_workers=args.workers, pin_memory=True)
         run_validate(aux_val_loader, len(val_loader))
 
@@ -490,7 +574,7 @@ def accuracy(output, target, topk=(1,)):
     """Computes the accuracy over the k top predictions for the specified values of k"""
     with torch.no_grad():
         maxk = max(topk)
-        batch_size = target.size(0)
+        batch_size = 112
 
         _, pred = output.topk(maxk, 1, True, True)
         pred = pred.t()
